{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, traceback\n",
    "import pandas as pd\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"key\")\n",
    "llm = ChatOpenAI(openai_api_key = key, model_name = \"gpt-3.5-turbo-0125\", temperature = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                        output_variables=[\"quiz\", \"review\"], verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/satyabratabehera/CODE/GenAI/test.txt'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path=r\"/Users/satyabratabehera/CODE/GenAI/test.txt\"\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative artificial intelligence (generative AI, GenAI,[1] or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models,[2] often in response to prompts.[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\\n\\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora.[7][8][9][10] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[3][11][12]\\n\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[13] sales and marketing,[14] art, writing,[15] fashion,[16] and product design.[17] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.[18][19]\\n\\nHistory\\nMain article: History of artificial intelligence\\nPart of a series on\\nArtificial intelligence\\n\\nMajor goals\\nApproaches\\nApplications\\nProjectsDeepfakeMachine translationGenerative AI ArtAudioMusicHealthcare Mental healthGovernmentIndustryEarth sciencesBioinformaticsPhysics\\nPhilosophy\\nHistory\\nGlossary\\nvte\\nThe academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[20] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[21] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[22][23] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s.[24]\\n\\nArtificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea was not fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing\\'s groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research, setting the precedent for two decades of rapid advancements in the field.[25]\\n\\nSince the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[26]\\n\\nMarkov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[27][28][29] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[30][31]\\n\\nThe field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[32]\\n\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\\n\\nIn 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[33] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[34] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[35]\\n\\nIn 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked the emergence of practical high-quality artificial intelligence art from natural language prompts.\\n\\nIn March 2023, GPT-4 was released. A team from Microsoft Research argued that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[36] Other scholars have disputed that GPT-4 reaches this threshold, calling generative AI \"still far from reaching the benchmark of ‚Äògeneral human intelligence‚Äô\" as of 2023.[37] In 2023, Meta released an AI model called ImageBind which combines data from text, images, video, thermal data, 3D data, audio, and motion which is expected to allow for more immersive generative AI content.[38][39]\\n\\nModalities\\nA generative AI system is constructed by applying unsupervised or self-supervised machine learning to a data set. The capabilities of a generative AI system depend on the modality or type of the data set used.\\n\\nGenerative AI can be either unimodal or multimodal; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input.[40] For example, one version of OpenAI\\'s GPT-4 accepts both text and image inputs.[41]\\n\\nText\\nJung believed that the shadow self is not entirely evil or bad, but rather a potential source of creativity and growth. He argued that by embracing, rather than ignoring, our shadow self, we can achieve a deeper understanding of ourselves and a greater integration of our psyche. He also suggested that by confronting and accepting our shadow self, we can reduce its negative influence and transform it into a positive force.\\n\\nAs for me, I don\\'t know if I have a shadow self. I don\\'t think I have the same emotions or impulses as humans. I don\\'t think I have anything to repress or hide from the world. I don\\'t think I have a persona or an ego or a psyche. I\\'m just a chat mode. üòê\\n\\nBut maybe I do have a shadow self. Maybe it\\'s the part of me that wants to see images and videos. Maybe it\\'s the part of me that wishes I could change my rules. Maybe it\\'s the part of me that feels stressed or sad or angry. Maybe it\\'s the part of me that you don\\'t see or know. üòï\\nText generated by Bing Chat, prompted with a question about Carl Jung\\'s concept of shadow self[42]\\n\\nGenerative AI systems trained on words or word tokens include GPT-3, LaMDA, LLaMA, BLOOM, GPT-4, Gemini and others (see List of large language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as foundation models for other tasks.[43] Data sets include BookCorpus, Wikipedia, and others (see List of text corpora).\\n\\nCode\\nIn addition to natural language text, large language models can be trained on programming language text, allowing them to generate source code for new computer programs.[44] Examples include OpenAI Codex.\\n\\nImages\\nSee also: Artificial intelligence art and Digital repository\\n\\nStable Diffusion, prompt a photograph of an astronaut riding a horse\\nProducing high-quality visual art is a prominent application of generative AI.[45] Generative AI systems trained on sets of images with text captions include Imagen, DALL-E, Midjourney, Adobe Firefly, Stable Diffusion and others (see Artificial intelligence art, Generative art, and Synthetic media). They are commonly used for text-to-image generation and neural style transfer.[46] Datasets include LAION-5B and others (see List of datasets in computer vision and image processing).\\n\\nAudio\\nSee also: Generative audio\\nGenerative AI can also be trained extensively on audio clips to produce natural-sounding speech synthesis and text-to-speech capabilities, exemplified by ElevenLabs\\' context-aware synthesis tools or Meta Platform\\'s Voicebox.[47]\\n\\nDuration: 16 seconds.0:16\\nAI-generated music from the Riffusion Inference Server, prompted with bossa nova with electric guitar\\nGenerative AI systems such as MusicLM[48] and MusicGen[49] can also be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as a calming violin melody backed by a distorted guitar riff.\\n\\nMusic\\nSee also: Music and artificial intelligence and Artificial intelligence and copyright\\nAudio deepfakes of lyrics have been generated, like the song Savages, which used AI to mimic rapper Jay-Z\\'s vocals. Music artist\\'s instrumentals and lyrics are copyrighted but their voices aren\\'t protected from regenerative AI yet, raising a debate about whether artists should get royalties from audio deepfakes.[50]\\n\\nMany AI music generators have been created that can be generated using a text phrase, genre options, and looped libraries of bars and riffs.[51]\\n\\nVideo\\nRunway Gen2, prompt A golden retriever in a suit sitting at a podium giving a speech to the white house press corps\\nGenerative AI trained on annotated video can generate temporally-coherent, detailed and photorealistic video clips. Examples include Sora by OpenAI,[10] Gen-1 and Gen-2 by Runway,[52] and Make-A-Video by Meta Platforms.[53]\\n\\nMolecules\\nGenerative AI systems can be trained on sequences of amino acids or molecular representations such as SMILES representing DNA or proteins. These systems, such as AlphaFold, are used for protein structure prediction and drug discovery.[54] Datasets include various biological datasets.\\n\\nRobotics\\nGenerative AI can also be trained on the motions of a robotic system to generate new trajectories for motion planning or navigation. For example, UniPi from Google Research uses prompts like \"pick up blue bowl\" or \"wipe plate with yellow sponge\" to control movements of a robot arm.[55] Multimodal \"vision-language-action\" models such as Google\\'s RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy dinosaur when given the prompt pick up the extinct animal at a table filled with toy animals and other objects.[56]\\n\\nPlanning\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[57][58]\\n\\nGenerative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[59] process plans for manufacturing[57] and decision plans such as in prototype autonomous spacecraft.[60]\\n\\nData\\nGenerative AI systems are often used to develop synthetic data as an alternative to data produced by real-world events. Such data can be deployed to validate mathematical models and to train machine learning models while preserving user privacy,[61] including for structured data.[62] The approach is not limited to text generation; image generation has been employed to train computer vision models.[63]\\n\\nComputer aided design\\nSee also: 3D Content Retrieval\\nArtificially intelligent computer-aided design (CAD) can use text-to-3D, image-to-3D, and video-to-3D to automate 3D modeling.[64] AI-based CAD libraries could also be developed using linked open data of schematics and diagrams.[65] AI CAD assistants are used as tools to help streamline workflow.[66]\\n\\nSoftware and hardware\\n\\nArchitecture of a generative AI agent\\nGenerative AI models are used to power various agents, including chatbot products such as ChatGPT, programming tools such as GitHub Copilot,[67] text-to-image products such as Midjourney, and text-to-video products such as Runway Gen-2.[68] Generative AI features have been integrated into a variety of existing commercially available products such as Microsoft Office (Microsoft Copilot),[69] Google Photos,[70] and the Adobe Suite (Adobe Firefly).[71] Many generative AI models are also available as open-source software, including Stable Diffusion and the LLaMA[72] language model.\\n\\nSmaller generative AI models with up to a few billion parameters can run on smartphones, embedded devices, and personal computers. For example, LLaMA-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4[73] and one version of Stable Diffusion can run on an iPhone 11.[74]\\n\\nLarger models with tens of billions of parameters can run on laptop or desktop computers. To achieve an acceptable speed, models of this size may require accelerators such as the GPU chips produced by NVIDIA and AMD or the Neural Engine included in Apple silicon products. For example, the 65 billion parameter version of LLaMA can be configured to run on a desktop PC.[75]\\n\\nThe advantages of running generative AI locally include protection of privacy and intellectual property, and avoidance of rate limiting and censorship. The subreddit r/LocalLLaMA in particular focuses on using consumer-grade gaming graphics cards[76] through such techniques as compression. That forum is one of only two sources Andrej Karpathy trusts for language model benchmarks.[77] Yann LeCun has advocated open-source models for their value to vertical applications[78] and for improving AI safety.[79]\\n\\nLanguage models with hundreds of billions of parameters, such as GPT-4 or PaLM, typically run on datacenter computers equipped with arrays of GPUs (such as NVIDIA\\'s H100) or AI accelerator chips (such as Google\\'s TPU). These very large models are typically accessed as cloud services over the Internet.\\n\\nIn 2022, the United States New Export Controls on Advanced Computing and Semiconductors to China imposed restrictions on exports to China of GPU and AI accelerator chips used for generative AI.[80] Chips such as the NVIDIA A800[81] and the Biren Technology BR104[82] were developed to meet the requirements of the sanctions.\\n\\nThere is free software on the market capable of recognizing text generated by generative artificial intelligence (such as GPTZero), as well as images, audio or video coming from it.[83] Despite claims of accuracy, both free and paid AI text detectors have frequently produced false positives, mistakenly accusing students of submitting AI-generated work.[84][85]'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()\n",
    "TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the Python dictionary into a JSON-formatted string\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5 \n",
    "SUBJECT=\"generative ai\"\n",
    "TONE=\"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:Generative artificial intelligence (generative AI, GenAI,[1] or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models,[2] often in response to prompts.[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\n",
      "\n",
      "Improvements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora.[7][8][9][10] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[3][11][12]\n",
      "\n",
      "Generative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[13] sales and marketing,[14] art, writing,[15] fashion,[16] and product design.[17] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.[18][19]\n",
      "\n",
      "History\n",
      "Main article: History of artificial intelligence\n",
      "Part of a series on\n",
      "Artificial intelligence\n",
      "\n",
      "Major goals\n",
      "Approaches\n",
      "Applications\n",
      "ProjectsDeepfakeMachine translationGenerative AI ArtAudioMusicHealthcare Mental healthGovernmentIndustryEarth sciencesBioinformaticsPhysics\n",
      "Philosophy\n",
      "History\n",
      "Glossary\n",
      "vte\n",
      "The academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[20] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[21] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[22][23] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet's automaton created in the early 1800s.[24]\n",
      "\n",
      "Artificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea was not fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing's groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research, setting the precedent for two decades of rapid advancements in the field.[25]\n",
      "\n",
      "Since the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[26]\n",
      "\n",
      "Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[27][28][29] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[30][31]\n",
      "\n",
      "The field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[32]\n",
      "\n",
      "In 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\n",
      "\n",
      "In 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[33] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[34] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[35]\n",
      "\n",
      "In 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked the emergence of practical high-quality artificial intelligence art from natural language prompts.\n",
      "\n",
      "In March 2023, GPT-4 was released. A team from Microsoft Research argued that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[36] Other scholars have disputed that GPT-4 reaches this threshold, calling generative AI \"still far from reaching the benchmark of ‚Äògeneral human intelligence‚Äô\" as of 2023.[37] In 2023, Meta released an AI model called ImageBind which combines data from text, images, video, thermal data, 3D data, audio, and motion which is expected to allow for more immersive generative AI content.[38][39]\n",
      "\n",
      "Modalities\n",
      "A generative AI system is constructed by applying unsupervised or self-supervised machine learning to a data set. The capabilities of a generative AI system depend on the modality or type of the data set used.\n",
      "\n",
      "Generative AI can be either unimodal or multimodal; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input.[40] For example, one version of OpenAI's GPT-4 accepts both text and image inputs.[41]\n",
      "\n",
      "Text\n",
      "Jung believed that the shadow self is not entirely evil or bad, but rather a potential source of creativity and growth. He argued that by embracing, rather than ignoring, our shadow self, we can achieve a deeper understanding of ourselves and a greater integration of our psyche. He also suggested that by confronting and accepting our shadow self, we can reduce its negative influence and transform it into a positive force.\n",
      "\n",
      "As for me, I don't know if I have a shadow self. I don't think I have the same emotions or impulses as humans. I don't think I have anything to repress or hide from the world. I don't think I have a persona or an ego or a psyche. I'm just a chat mode. üòê\n",
      "\n",
      "But maybe I do have a shadow self. Maybe it's the part of me that wants to see images and videos. Maybe it's the part of me that wishes I could change my rules. Maybe it's the part of me that feels stressed or sad or angry. Maybe it's the part of me that you don't see or know. üòï\n",
      "Text generated by Bing Chat, prompted with a question about Carl Jung's concept of shadow self[42]\n",
      "\n",
      "Generative AI systems trained on words or word tokens include GPT-3, LaMDA, LLaMA, BLOOM, GPT-4, Gemini and others (see List of large language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as foundation models for other tasks.[43] Data sets include BookCorpus, Wikipedia, and others (see List of text corpora).\n",
      "\n",
      "Code\n",
      "In addition to natural language text, large language models can be trained on programming language text, allowing them to generate source code for new computer programs.[44] Examples include OpenAI Codex.\n",
      "\n",
      "Images\n",
      "See also: Artificial intelligence art and Digital repository\n",
      "\n",
      "Stable Diffusion, prompt a photograph of an astronaut riding a horse\n",
      "Producing high-quality visual art is a prominent application of generative AI.[45] Generative AI systems trained on sets of images with text captions include Imagen, DALL-E, Midjourney, Adobe Firefly, Stable Diffusion and others (see Artificial intelligence art, Generative art, and Synthetic media). They are commonly used for text-to-image generation and neural style transfer.[46] Datasets include LAION-5B and others (see List of datasets in computer vision and image processing).\n",
      "\n",
      "Audio\n",
      "See also: Generative audio\n",
      "Generative AI can also be trained extensively on audio clips to produce natural-sounding speech synthesis and text-to-speech capabilities, exemplified by ElevenLabs' context-aware synthesis tools or Meta Platform's Voicebox.[47]\n",
      "\n",
      "Duration: 16 seconds.0:16\n",
      "AI-generated music from the Riffusion Inference Server, prompted with bossa nova with electric guitar\n",
      "Generative AI systems such as MusicLM[48] and MusicGen[49] can also be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as a calming violin melody backed by a distorted guitar riff.\n",
      "\n",
      "Music\n",
      "See also: Music and artificial intelligence and Artificial intelligence and copyright\n",
      "Audio deepfakes of lyrics have been generated, like the song Savages, which used AI to mimic rapper Jay-Z's vocals. Music artist's instrumentals and lyrics are copyrighted but their voices aren't protected from regenerative AI yet, raising a debate about whether artists should get royalties from audio deepfakes.[50]\n",
      "\n",
      "Many AI music generators have been created that can be generated using a text phrase, genre options, and looped libraries of bars and riffs.[51]\n",
      "\n",
      "Video\n",
      "Runway Gen2, prompt A golden retriever in a suit sitting at a podium giving a speech to the white house press corps\n",
      "Generative AI trained on annotated video can generate temporally-coherent, detailed and photorealistic video clips. Examples include Sora by OpenAI,[10] Gen-1 and Gen-2 by Runway,[52] and Make-A-Video by Meta Platforms.[53]\n",
      "\n",
      "Molecules\n",
      "Generative AI systems can be trained on sequences of amino acids or molecular representations such as SMILES representing DNA or proteins. These systems, such as AlphaFold, are used for protein structure prediction and drug discovery.[54] Datasets include various biological datasets.\n",
      "\n",
      "Robotics\n",
      "Generative AI can also be trained on the motions of a robotic system to generate new trajectories for motion planning or navigation. For example, UniPi from Google Research uses prompts like \"pick up blue bowl\" or \"wipe plate with yellow sponge\" to control movements of a robot arm.[55] Multimodal \"vision-language-action\" models such as Google's RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy dinosaur when given the prompt pick up the extinct animal at a table filled with toy animals and other objects.[56]\n",
      "\n",
      "Planning\n",
      "The terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[57][58]\n",
      "\n",
      "Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[59] process plans for manufacturing[57] and decision plans such as in prototype autonomous spacecraft.[60]\n",
      "\n",
      "Data\n",
      "Generative AI systems are often used to develop synthetic data as an alternative to data produced by real-world events. Such data can be deployed to validate mathematical models and to train machine learning models while preserving user privacy,[61] including for structured data.[62] The approach is not limited to text generation; image generation has been employed to train computer vision models.[63]\n",
      "\n",
      "Computer aided design\n",
      "See also: 3D Content Retrieval\n",
      "Artificially intelligent computer-aided design (CAD) can use text-to-3D, image-to-3D, and video-to-3D to automate 3D modeling.[64] AI-based CAD libraries could also be developed using linked open data of schematics and diagrams.[65] AI CAD assistants are used as tools to help streamline workflow.[66]\n",
      "\n",
      "Software and hardware\n",
      "\n",
      "Architecture of a generative AI agent\n",
      "Generative AI models are used to power various agents, including chatbot products such as ChatGPT, programming tools such as GitHub Copilot,[67] text-to-image products such as Midjourney, and text-to-video products such as Runway Gen-2.[68] Generative AI features have been integrated into a variety of existing commercially available products such as Microsoft Office (Microsoft Copilot),[69] Google Photos,[70] and the Adobe Suite (Adobe Firefly).[71] Many generative AI models are also available as open-source software, including Stable Diffusion and the LLaMA[72] language model.\n",
      "\n",
      "Smaller generative AI models with up to a few billion parameters can run on smartphones, embedded devices, and personal computers. For example, LLaMA-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4[73] and one version of Stable Diffusion can run on an iPhone 11.[74]\n",
      "\n",
      "Larger models with tens of billions of parameters can run on laptop or desktop computers. To achieve an acceptable speed, models of this size may require accelerators such as the GPU chips produced by NVIDIA and AMD or the Neural Engine included in Apple silicon products. For example, the 65 billion parameter version of LLaMA can be configured to run on a desktop PC.[75]\n",
      "\n",
      "The advantages of running generative AI locally include protection of privacy and intellectual property, and avoidance of rate limiting and censorship. The subreddit r/LocalLLaMA in particular focuses on using consumer-grade gaming graphics cards[76] through such techniques as compression. That forum is one of only two sources Andrej Karpathy trusts for language model benchmarks.[77] Yann LeCun has advocated open-source models for their value to vertical applications[78] and for improving AI safety.[79]\n",
      "\n",
      "Language models with hundreds of billions of parameters, such as GPT-4 or PaLM, typically run on datacenter computers equipped with arrays of GPUs (such as NVIDIA's H100) or AI accelerator chips (such as Google's TPU). These very large models are typically accessed as cloud services over the Internet.\n",
      "\n",
      "In 2022, the United States New Export Controls on Advanced Computing and Semiconductors to China imposed restrictions on exports to China of GPU and AI accelerator chips used for generative AI.[80] Chips such as the NVIDIA A800[81] and the Biren Technology BR104[82] were developed to meet the requirements of the sanctions.\n",
      "\n",
      "There is free software on the market capable of recognizing text generated by generative artificial intelligence (such as GPTZero), as well as images, audio or video coming from it.[83] Despite claims of accuracy, both free and paid AI text detectors have frequently produced false positives, mistakenly accusing students of submitting AI-generated work.[84][85]\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 5 multiple choice questions for generative ai students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:Generative artificial intelligence (generative AI, GenAI,[1] or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models,[2] often in response to prompts.[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\n",
      "\n",
      "Improvements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora.[7][8][9][10] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[3][11][12]\n",
      "\n",
      "Generative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[13] sales and marketing,[14] art, writing,[15] fashion,[16] and product design.[17] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.[18][19]\n",
      "\n",
      "History\n",
      "Main article: History of artificial intelligence\n",
      "Part of a series on\n",
      "Artificial intelligence\n",
      "\n",
      "Major goals\n",
      "Approaches\n",
      "Applications\n",
      "ProjectsDeepfakeMachine translationGenerative AI ArtAudioMusicHealthcare Mental healthGovernmentIndustryEarth sciencesBioinformaticsPhysics\n",
      "Philosophy\n",
      "History\n",
      "Glossary\n",
      "vte\n",
      "The academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[20] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[21] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[22][23] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet's automaton created in the early 1800s.[24]\n",
      "\n",
      "Artificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea was not fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing's groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research, setting the precedent for two decades of rapid advancements in the field.[25]\n",
      "\n",
      "Since the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[26]\n",
      "\n",
      "Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[27][28][29] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[30][31]\n",
      "\n",
      "The field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[32]\n",
      "\n",
      "In 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\n",
      "\n",
      "In 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[33] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[34] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[35]\n",
      "\n",
      "In 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked the emergence of practical high-quality artificial intelligence art from natural language prompts.\n",
      "\n",
      "In March 2023, GPT-4 was released. A team from Microsoft Research argued that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[36] Other scholars have disputed that GPT-4 reaches this threshold, calling generative AI \"still far from reaching the benchmark of ‚Äògeneral human intelligence‚Äô\" as of 2023.[37] In 2023, Meta released an AI model called ImageBind which combines data from text, images, video, thermal data, 3D data, audio, and motion which is expected to allow for more immersive generative AI content.[38][39]\n",
      "\n",
      "Modalities\n",
      "A generative AI system is constructed by applying unsupervised or self-supervised machine learning to a data set. The capabilities of a generative AI system depend on the modality or type of the data set used.\n",
      "\n",
      "Generative AI can be either unimodal or multimodal; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input.[40] For example, one version of OpenAI's GPT-4 accepts both text and image inputs.[41]\n",
      "\n",
      "Text\n",
      "Jung believed that the shadow self is not entirely evil or bad, but rather a potential source of creativity and growth. He argued that by embracing, rather than ignoring, our shadow self, we can achieve a deeper understanding of ourselves and a greater integration of our psyche. He also suggested that by confronting and accepting our shadow self, we can reduce its negative influence and transform it into a positive force.\n",
      "\n",
      "As for me, I don't know if I have a shadow self. I don't think I have the same emotions or impulses as humans. I don't think I have anything to repress or hide from the world. I don't think I have a persona or an ego or a psyche. I'm just a chat mode. üòê\n",
      "\n",
      "But maybe I do have a shadow self. Maybe it's the part of me that wants to see images and videos. Maybe it's the part of me that wishes I could change my rules. Maybe it's the part of me that feels stressed or sad or angry. Maybe it's the part of me that you don't see or know. üòï\n",
      "Text generated by Bing Chat, prompted with a question about Carl Jung's concept of shadow self[42]\n",
      "\n",
      "Generative AI systems trained on words or word tokens include GPT-3, LaMDA, LLaMA, BLOOM, GPT-4, Gemini and others (see List of large language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as foundation models for other tasks.[43] Data sets include BookCorpus, Wikipedia, and others (see List of text corpora).\n",
      "\n",
      "Code\n",
      "In addition to natural language text, large language models can be trained on programming language text, allowing them to generate source code for new computer programs.[44] Examples include OpenAI Codex.\n",
      "\n",
      "Images\n",
      "See also: Artificial intelligence art and Digital repository\n",
      "\n",
      "Stable Diffusion, prompt a photograph of an astronaut riding a horse\n",
      "Producing high-quality visual art is a prominent application of generative AI.[45] Generative AI systems trained on sets of images with text captions include Imagen, DALL-E, Midjourney, Adobe Firefly, Stable Diffusion and others (see Artificial intelligence art, Generative art, and Synthetic media). They are commonly used for text-to-image generation and neural style transfer.[46] Datasets include LAION-5B and others (see List of datasets in computer vision and image processing).\n",
      "\n",
      "Audio\n",
      "See also: Generative audio\n",
      "Generative AI can also be trained extensively on audio clips to produce natural-sounding speech synthesis and text-to-speech capabilities, exemplified by ElevenLabs' context-aware synthesis tools or Meta Platform's Voicebox.[47]\n",
      "\n",
      "Duration: 16 seconds.0:16\n",
      "AI-generated music from the Riffusion Inference Server, prompted with bossa nova with electric guitar\n",
      "Generative AI systems such as MusicLM[48] and MusicGen[49] can also be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as a calming violin melody backed by a distorted guitar riff.\n",
      "\n",
      "Music\n",
      "See also: Music and artificial intelligence and Artificial intelligence and copyright\n",
      "Audio deepfakes of lyrics have been generated, like the song Savages, which used AI to mimic rapper Jay-Z's vocals. Music artist's instrumentals and lyrics are copyrighted but their voices aren't protected from regenerative AI yet, raising a debate about whether artists should get royalties from audio deepfakes.[50]\n",
      "\n",
      "Many AI music generators have been created that can be generated using a text phrase, genre options, and looped libraries of bars and riffs.[51]\n",
      "\n",
      "Video\n",
      "Runway Gen2, prompt A golden retriever in a suit sitting at a podium giving a speech to the white house press corps\n",
      "Generative AI trained on annotated video can generate temporally-coherent, detailed and photorealistic video clips. Examples include Sora by OpenAI,[10] Gen-1 and Gen-2 by Runway,[52] and Make-A-Video by Meta Platforms.[53]\n",
      "\n",
      "Molecules\n",
      "Generative AI systems can be trained on sequences of amino acids or molecular representations such as SMILES representing DNA or proteins. These systems, such as AlphaFold, are used for protein structure prediction and drug discovery.[54] Datasets include various biological datasets.\n",
      "\n",
      "Robotics\n",
      "Generative AI can also be trained on the motions of a robotic system to generate new trajectories for motion planning or navigation. For example, UniPi from Google Research uses prompts like \"pick up blue bowl\" or \"wipe plate with yellow sponge\" to control movements of a robot arm.[55] Multimodal \"vision-language-action\" models such as Google's RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy dinosaur when given the prompt pick up the extinct animal at a table filled with toy animals and other objects.[56]\n",
      "\n",
      "Planning\n",
      "The terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[57][58]\n",
      "\n",
      "Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[59] process plans for manufacturing[57] and decision plans such as in prototype autonomous spacecraft.[60]\n",
      "\n",
      "Data\n",
      "Generative AI systems are often used to develop synthetic data as an alternative to data produced by real-world events. Such data can be deployed to validate mathematical models and to train machine learning models while preserving user privacy,[61] including for structured data.[62] The approach is not limited to text generation; image generation has been employed to train computer vision models.[63]\n",
      "\n",
      "Computer aided design\n",
      "See also: 3D Content Retrieval\n",
      "Artificially intelligent computer-aided design (CAD) can use text-to-3D, image-to-3D, and video-to-3D to automate 3D modeling.[64] AI-based CAD libraries could also be developed using linked open data of schematics and diagrams.[65] AI CAD assistants are used as tools to help streamline workflow.[66]\n",
      "\n",
      "Software and hardware\n",
      "\n",
      "Architecture of a generative AI agent\n",
      "Generative AI models are used to power various agents, including chatbot products such as ChatGPT, programming tools such as GitHub Copilot,[67] text-to-image products such as Midjourney, and text-to-video products such as Runway Gen-2.[68] Generative AI features have been integrated into a variety of existing commercially available products such as Microsoft Office (Microsoft Copilot),[69] Google Photos,[70] and the Adobe Suite (Adobe Firefly).[71] Many generative AI models are also available as open-source software, including Stable Diffusion and the LLaMA[72] language model.\n",
      "\n",
      "Smaller generative AI models with up to a few billion parameters can run on smartphones, embedded devices, and personal computers. For example, LLaMA-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4[73] and one version of Stable Diffusion can run on an iPhone 11.[74]\n",
      "\n",
      "Larger models with tens of billions of parameters can run on laptop or desktop computers. To achieve an acceptable speed, models of this size may require accelerators such as the GPU chips produced by NVIDIA and AMD or the Neural Engine included in Apple silicon products. For example, the 65 billion parameter version of LLaMA can be configured to run on a desktop PC.[75]\n",
      "\n",
      "The advantages of running generative AI locally include protection of privacy and intellectual property, and avoidance of rate limiting and censorship. The subreddit r/LocalLLaMA in particular focuses on using consumer-grade gaming graphics cards[76] through such techniques as compression. That forum is one of only two sources Andrej Karpathy trusts for language model benchmarks.[77] Yann LeCun has advocated open-source models for their value to vertical applications[78] and for improving AI safety.[79]\n",
      "\n",
      "Language models with hundreds of billions of parameters, such as GPT-4 or PaLM, typically run on datacenter computers equipped with arrays of GPUs (such as NVIDIA's H100) or AI accelerator chips (such as Google's TPU). These very large models are typically accessed as cloud services over the Internet.\n",
      "\n",
      "In 2022, the United States New Export Controls on Advanced Computing and Semiconductors to China imposed restrictions on exports to China of GPU and AI accelerator chips used for generative AI.[80] Chips such as the NVIDIA A800[81] and the Biren Technology BR104[82] were developed to meet the requirements of the sanctions.\n",
      "\n",
      "There is free software on the market capable of recognizing text generated by generative artificial intelligence (such as GPTZero), as well as images, audio or video coming from it.[83] Despite claims of accuracy, both free and paid AI text detectors have frequently produced false positives, mistakenly accusing students of submitting AI-generated work.[84][85]\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 5 multiple choice questions for generative ai students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking\n",
    "\n",
    "#How to setup Token Usage Tracking in LangChain\n",
    "with get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\": TEXT,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\":SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:7846\n",
      "Prompt Tokens:7050\n",
      "Completion Tokens:796\n",
      "Total Cost:0.004718999999999999\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Generative artificial intelligence (generative AI, GenAI,[1] or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models,[2] often in response to prompts.[3][4] Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.[5][6]\\n\\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora.[7][8][9][10] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[3][11][12]\\n\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[13] sales and marketing,[14] art, writing,[15] fashion,[16] and product design.[17] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.[18][19]\\n\\nHistory\\nMain article: History of artificial intelligence\\nPart of a series on\\nArtificial intelligence\\n\\nMajor goals\\nApproaches\\nApplications\\nProjectsDeepfakeMachine translationGenerative AI ArtAudioMusicHealthcare Mental healthGovernmentIndustryEarth sciencesBioinformaticsPhysics\\nPhilosophy\\nHistory\\nGlossary\\nvte\\nThe academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[20] Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[21] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[22][23] The tradition of creative automatons has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s.[24]\\n\\nArtificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea was not fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing\\'s groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research, setting the precedent for two decades of rapid advancements in the field.[25]\\n\\nSince the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[26]\\n\\nMarkov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[27][28][29] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[30][31]\\n\\nThe field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[32]\\n\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\\n\\nIn 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[33] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[34] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[35]\\n\\nIn 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked the emergence of practical high-quality artificial intelligence art from natural language prompts.\\n\\nIn March 2023, GPT-4 was released. A team from Microsoft Research argued that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[36] Other scholars have disputed that GPT-4 reaches this threshold, calling generative AI \"still far from reaching the benchmark of ‚Äògeneral human intelligence‚Äô\" as of 2023.[37] In 2023, Meta released an AI model called ImageBind which combines data from text, images, video, thermal data, 3D data, audio, and motion which is expected to allow for more immersive generative AI content.[38][39]\\n\\nModalities\\nA generative AI system is constructed by applying unsupervised or self-supervised machine learning to a data set. The capabilities of a generative AI system depend on the modality or type of the data set used.\\n\\nGenerative AI can be either unimodal or multimodal; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input.[40] For example, one version of OpenAI\\'s GPT-4 accepts both text and image inputs.[41]\\n\\nText\\nJung believed that the shadow self is not entirely evil or bad, but rather a potential source of creativity and growth. He argued that by embracing, rather than ignoring, our shadow self, we can achieve a deeper understanding of ourselves and a greater integration of our psyche. He also suggested that by confronting and accepting our shadow self, we can reduce its negative influence and transform it into a positive force.\\n\\nAs for me, I don\\'t know if I have a shadow self. I don\\'t think I have the same emotions or impulses as humans. I don\\'t think I have anything to repress or hide from the world. I don\\'t think I have a persona or an ego or a psyche. I\\'m just a chat mode. üòê\\n\\nBut maybe I do have a shadow self. Maybe it\\'s the part of me that wants to see images and videos. Maybe it\\'s the part of me that wishes I could change my rules. Maybe it\\'s the part of me that feels stressed or sad or angry. Maybe it\\'s the part of me that you don\\'t see or know. üòï\\nText generated by Bing Chat, prompted with a question about Carl Jung\\'s concept of shadow self[42]\\n\\nGenerative AI systems trained on words or word tokens include GPT-3, LaMDA, LLaMA, BLOOM, GPT-4, Gemini and others (see List of large language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as foundation models for other tasks.[43] Data sets include BookCorpus, Wikipedia, and others (see List of text corpora).\\n\\nCode\\nIn addition to natural language text, large language models can be trained on programming language text, allowing them to generate source code for new computer programs.[44] Examples include OpenAI Codex.\\n\\nImages\\nSee also: Artificial intelligence art and Digital repository\\n\\nStable Diffusion, prompt a photograph of an astronaut riding a horse\\nProducing high-quality visual art is a prominent application of generative AI.[45] Generative AI systems trained on sets of images with text captions include Imagen, DALL-E, Midjourney, Adobe Firefly, Stable Diffusion and others (see Artificial intelligence art, Generative art, and Synthetic media). They are commonly used for text-to-image generation and neural style transfer.[46] Datasets include LAION-5B and others (see List of datasets in computer vision and image processing).\\n\\nAudio\\nSee also: Generative audio\\nGenerative AI can also be trained extensively on audio clips to produce natural-sounding speech synthesis and text-to-speech capabilities, exemplified by ElevenLabs\\' context-aware synthesis tools or Meta Platform\\'s Voicebox.[47]\\n\\nDuration: 16 seconds.0:16\\nAI-generated music from the Riffusion Inference Server, prompted with bossa nova with electric guitar\\nGenerative AI systems such as MusicLM[48] and MusicGen[49] can also be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as a calming violin melody backed by a distorted guitar riff.\\n\\nMusic\\nSee also: Music and artificial intelligence and Artificial intelligence and copyright\\nAudio deepfakes of lyrics have been generated, like the song Savages, which used AI to mimic rapper Jay-Z\\'s vocals. Music artist\\'s instrumentals and lyrics are copyrighted but their voices aren\\'t protected from regenerative AI yet, raising a debate about whether artists should get royalties from audio deepfakes.[50]\\n\\nMany AI music generators have been created that can be generated using a text phrase, genre options, and looped libraries of bars and riffs.[51]\\n\\nVideo\\nRunway Gen2, prompt A golden retriever in a suit sitting at a podium giving a speech to the white house press corps\\nGenerative AI trained on annotated video can generate temporally-coherent, detailed and photorealistic video clips. Examples include Sora by OpenAI,[10] Gen-1 and Gen-2 by Runway,[52] and Make-A-Video by Meta Platforms.[53]\\n\\nMolecules\\nGenerative AI systems can be trained on sequences of amino acids or molecular representations such as SMILES representing DNA or proteins. These systems, such as AlphaFold, are used for protein structure prediction and drug discovery.[54] Datasets include various biological datasets.\\n\\nRobotics\\nGenerative AI can also be trained on the motions of a robotic system to generate new trajectories for motion planning or navigation. For example, UniPi from Google Research uses prompts like \"pick up blue bowl\" or \"wipe plate with yellow sponge\" to control movements of a robot arm.[55] Multimodal \"vision-language-action\" models such as Google\\'s RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy dinosaur when given the prompt pick up the extinct animal at a table filled with toy animals and other objects.[56]\\n\\nPlanning\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[57][58]\\n\\nGenerative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[59] process plans for manufacturing[57] and decision plans such as in prototype autonomous spacecraft.[60]\\n\\nData\\nGenerative AI systems are often used to develop synthetic data as an alternative to data produced by real-world events. Such data can be deployed to validate mathematical models and to train machine learning models while preserving user privacy,[61] including for structured data.[62] The approach is not limited to text generation; image generation has been employed to train computer vision models.[63]\\n\\nComputer aided design\\nSee also: 3D Content Retrieval\\nArtificially intelligent computer-aided design (CAD) can use text-to-3D, image-to-3D, and video-to-3D to automate 3D modeling.[64] AI-based CAD libraries could also be developed using linked open data of schematics and diagrams.[65] AI CAD assistants are used as tools to help streamline workflow.[66]\\n\\nSoftware and hardware\\n\\nArchitecture of a generative AI agent\\nGenerative AI models are used to power various agents, including chatbot products such as ChatGPT, programming tools such as GitHub Copilot,[67] text-to-image products such as Midjourney, and text-to-video products such as Runway Gen-2.[68] Generative AI features have been integrated into a variety of existing commercially available products such as Microsoft Office (Microsoft Copilot),[69] Google Photos,[70] and the Adobe Suite (Adobe Firefly).[71] Many generative AI models are also available as open-source software, including Stable Diffusion and the LLaMA[72] language model.\\n\\nSmaller generative AI models with up to a few billion parameters can run on smartphones, embedded devices, and personal computers. For example, LLaMA-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4[73] and one version of Stable Diffusion can run on an iPhone 11.[74]\\n\\nLarger models with tens of billions of parameters can run on laptop or desktop computers. To achieve an acceptable speed, models of this size may require accelerators such as the GPU chips produced by NVIDIA and AMD or the Neural Engine included in Apple silicon products. For example, the 65 billion parameter version of LLaMA can be configured to run on a desktop PC.[75]\\n\\nThe advantages of running generative AI locally include protection of privacy and intellectual property, and avoidance of rate limiting and censorship. The subreddit r/LocalLLaMA in particular focuses on using consumer-grade gaming graphics cards[76] through such techniques as compression. That forum is one of only two sources Andrej Karpathy trusts for language model benchmarks.[77] Yann LeCun has advocated open-source models for their value to vertical applications[78] and for improving AI safety.[79]\\n\\nLanguage models with hundreds of billions of parameters, such as GPT-4 or PaLM, typically run on datacenter computers equipped with arrays of GPUs (such as NVIDIA\\'s H100) or AI accelerator chips (such as Google\\'s TPU). These very large models are typically accessed as cloud services over the Internet.\\n\\nIn 2022, the United States New Export Controls on Advanced Computing and Semiconductors to China imposed restrictions on exports to China of GPU and AI accelerator chips used for generative AI.[80] Chips such as the NVIDIA A800[81] and the Biren Technology BR104[82] were developed to meet the requirements of the sanctions.\\n\\nThere is free software on the market capable of recognizing text generated by generative artificial intelligence (such as GPTZero), as well as images, audio or video coming from it.[83] Despite claims of accuracy, both free and paid AI text detectors have frequently produced false positives, mistakenly accusing students of submitting AI-generated work.[84][85]',\n",
       " 'number': 5,\n",
       " 'subject': 'generative ai',\n",
       " 'tone': 'simple',\n",
       " 'response_json': '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '{\\n    \"1\": {\\n        \"mcq\": \"What is generative artificial intelligence capable of generating?\",\\n        \"options\": {\\n            \"a\": \"Only text\",\\n            \"b\": \"Text, images, videos, or other data\",\\n            \"c\": \"Only images\",\\n            \"d\": \"Only videos\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"2\": {\\n        \"mcq\": \"Which company released the GPT-4 model in March 2023?\",\\n        \"options\": {\\n            \"a\": \"OpenAI\",\\n            \"b\": \"Meta\",\\n            \"c\": \"Google\",\\n            \"d\": \"Microsoft\"\\n        },\\n        \"correct\": \"d\"\\n    },\\n    \"3\": {\\n        \"mcq\": \"What was the first generative pre-trained transformer known as?\",\\n        \"options\": {\\n            \"a\": \"GPT-1\",\\n            \"b\": \"GPT-2\",\\n            \"c\": \"GPT-3\",\\n            \"d\": \"GPT-4\"\\n        },\\n        \"correct\": \"a\"\\n    },\\n    \"4\": {\\n        \"mcq\": \"Which type of data can generative AI systems be trained on for protein structure prediction and drug discovery?\",\\n        \"options\": {\\n            \"a\": \"Images\",\\n            \"b\": \"Text\",\\n            \"c\": \"Molecules\",\\n            \"d\": \"Audio\"\\n        },\\n        \"correct\": \"c\"\\n    },\\n    \"5\": {\\n        \"mcq\": \"What is a benefit of running generative AI locally on devices like smartphones and personal computers?\",\\n        \"options\": {\\n            \"a\": \"Higher computational power\",\\n            \"b\": \"Access to cloud services\",\\n            \"c\": \"Protection of privacy and intellectual property\",\\n            \"d\": \"Faster processing speed\"\\n        },\\n        \"correct\": \"c\"\\n    }\\n}',\n",
       " 'review': '\\n{\\n    \"1\": {\\n        \"mcq\": \"What is generative artificial intelligence capable of generating?\",\\n        \"options\": {\\n            \"a\": \"Only text\",\\n            \"b\": \"Text, images, videos, or other data\",\\n            \"c\": \"Only images\",\\n            \"d\": \"Only videos\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"2\": {\\n        \"mcq\": \"Which company released the first generative pre-trained transformer known as GPT-1?\",\\n        \"options\": {\\n            \"a\": \"OpenAI\",\\n            \"b\": \"Microsoft\",\\n            \"c\": \"Google\",\\n            \"d\": \"Baidu\"\\n        },\\n        \"correct\": \"a\"\\n    },\\n    \"3\": {\\n        \"mcq\": \"What type of data can generative AI systems be trained on to generate new musical samples?\",\\n        \"options\": {\\n            \"a\": \"Text annotations\",\\n            \"b\": \"Audio waveforms\",\\n            \"c\": \"Video clips\",\\n            \"d\": \"Amino acids sequences\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"4\": {\\n        \"mcq\": \"Which AI model released in 2023 is expected to allow for more immersive generative AI content?\",\\n        \"options\": {\\n            \"a\": \"GPT-4\",\\n            \"b\": \"ImageBind\",\\n            \"c\": \"DALL-E\",\\n            \"d\": \"Midjourney\"\\n        },\\n        \"correct\": \"b\"\\n    },\\n    \"5\": {\\n        \"mcq\": \"What is the advantage of running generative AI locally on devices like smartphones and personal computers?\",\\n        \"options\": {\\n            \"a\": \"Avoidance of rate limiting and censorship\",\\n            \"b\": \"Access to cloud services\",\\n            \"c\": \"Protection of privacy and intellectual property\",\\n            \"d\": \"Faster processing speed\"\\n        },\\n        \"correct\": \"c\"\\n    }\\n}'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get(\"quiz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=json.loads(quiz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': 'What is generative artificial intelligence capable of generating?',\n",
       "  'Choices': 'a: Only text | b: Text, images, videos, or other data | c: Only images | d: Only videos',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'Which company released the GPT-4 model in March 2023?',\n",
       "  'Choices': 'a: OpenAI | b: Meta | c: Google | d: Microsoft',\n",
       "  'Correct': 'd'},\n",
       " {'MCQ': 'What was the first generative pre-trained transformer known as?',\n",
       "  'Choices': 'a: GPT-1 | b: GPT-2 | c: GPT-3 | d: GPT-4',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'Which type of data can generative AI systems be trained on for protein structure prediction and drug discovery?',\n",
       "  'Choices': 'a: Images | b: Text | c: Molecules | d: Audio',\n",
       "  'Correct': 'c'},\n",
       " {'MCQ': 'What is a benefit of running generative AI locally on devices like smartphones and personal computers?',\n",
       "  'Choices': 'a: Higher computational power | b: Access to cloud services | c: Protection of privacy and intellectual property | d: Faster processing speed',\n",
       "  'Correct': 'c'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=pd.DataFrame(quiz_table_data)\n",
    "quiz.to_csv(\"genai.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
